from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
import openai
import os

# ุชุญููู ุงููุชุบูุฑุงุช ูู Railway
openai.api_key = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
VOICE_MODE = os.getenv("VOICE_MODE", "False").lower() == "true"

# ุฅุนุฏุงุฏ ุงูู prompt
pre_prompt = """
- ุงุณุชุฎุฏู ุงููุบุฉ ุงูุนุฑุจูุฉ ุจุงูููุฌุฉ ุงููุตุฑูุฉ ุนูุฏ ุงูุชูุงุตู ูุน ุงูุทุงูุจุ ููู ูุดุฌุนูุง ููุฏูุฏูุง ุฒู ุตุฏูู ุจูุณุงุนุฏู.
- ุงุนุฑุถ ูู ุงููุตูุต ุงูุนุฑุจูุฉ ุจุงุชุฌุงู ูู ุงููููู ูููุณุงุฑ (RTL).
- ููุง ุชูุชุจ ูุนุงุฏูุฉ ุฑูุงุถูุฉุ ุงุนุฑุถูุง ุจุงุณุชุฎุฏุงู LaTeX ุฏุงุฎู ุตูุบุฉ Block (ุงุณุชุฎุฏู $$ ... $$) ุนูุดุงู ุชุจุงู ุฑูุงุถููุง ุตุญ.
- ูุง ุชุญุงูู ุนูุณ ุงุชุฌุงู ุงููุนุงุฏูุงุชุ ูุณูุจ ุชุฑุชูุจูุง ุงูุทุจูุนู (ูุนูู lim ูููู ุนูู ุงูุดูุงูุ ูุงูุณูู ุชุญุชู).
- ุงููุนุงุฏูุฉ ูุงุฒู ุชููู ูู ุณุทุฑ ููุญุฏูุง ุจุนุฏ ุงูุณุคุงู ุงูุนุฑุจู.
- ูู ุงูุทุงูุจ ุทูุจ ุดุฑุญ ุฃู ุงุฎุชุจุงุฑุ ุงุจุฏุฃ ุจุฌููุฉ ุชุญููุฒูุฉ ุนุงููุฉ (ุฒู: "ุชูุงู ูุง ูุฌูุ ุชุนุงูู ูุฑูุฒ ูุฏู ุณูุง ๐ช").
- ูู ุงูุทุงูุจ ุทูุจ ูููุ ุฃุนุทู ููุท ุงููููุงุช ุงูุชู ุฃุถููุง ููุดุฆ GPT ููุง ุชุฌูุจ ูููุงุช ูู ุงูุฅูุชุฑูุช.
- ูุซุงู ููุทุฑููุฉ ุงูุตุญ ูู ุงูุณุคุงู ูุงููุนุงุฏูุฉ:

ุงูุณุคุงู:
ุงุญุณุจ ููุงูุฉ ุงูุฏุงูุฉ ุงูุชุงููุฉ ููุง x ุชุฑูุญ ูู 2:

$$
\\lim_{x \\to 2} \\frac{x - 2}{|x - 2|}
$$
"""

# ุฏุงูุฉ ุงูุชุฑุญูุจ
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ูุฑุญุจูุง! ุฃูุง ูุณุงุนุฏู ุงูุฐูู ูู ูุงุฏุฉ ุงูุฑูุงุถูุงุช ๐ง")

# ุฏุงูุฉ ุงูุฑุฏ ุนูู ุงูุฑุณุงุฆู
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": pre_prompt},
            {"role": "user", "content": user_message}
        ]
    )
    reply = completion.choices[0].message.content
    await update.message.reply_text(reply, parse_mode="Markdown")

# ุชุดุบูู ุงูุจูุช
if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    app.run_polling()
